# ğŸ­ InduTechData - Cloud Architecture & Streaming ETL

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python&logoColor=white)
![Spark](https://img.shields.io/badge/Apache_Spark-Streaming-orange?logo=apachespark&logoColor=white)
![Redpanda](https://img.shields.io/badge/Redpanda-Kafka_Compatible-red)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)

Ce projet Data Engineering (Projet 9) se divise en deux volets complÃ©mentaires : la **modÃ©lisation d'une architecture Cloud Hybride** (AWS) pour une industrie IoT, et le **dÃ©veloppement d'un POC technique** (ETL Streaming) pour valider la stack technologique.

---

## ğŸ—ï¸ PARTIE 1 : Architecture Cloud Hybride (Design)

**Contexte :** Modernisation du SI d'InduTechData pour gÃ©rer des flux IoT massifs (50 Go/mois) et 40 To de donnÃ©es historiques.

**Objectif :** Concevoir une infrastructure sÃ©curisÃ©e reliant l'usine (On-Premise) au Cloud (AWS).

![Architecture Cloud](assets/P9_Choix_de_composants.png)

*   **Ingestion :** Redpanda pour la performance et la compatibilitÃ© Kafka.
*   **Stockage :** Data Lake sur **Amazon S3** (DonnÃ©es brutes) et Data Warehouse sur **Amazon Redshift** (Analytique).
*   **InteropÃ©rabilitÃ© :** Utilisation de **Redshift Spectrum** pour croiser les donnÃ©es chaudes (IoT) et froides (ERP SQL Server).
*   **SÃ©curitÃ© :** VPN Site-to-Site et extension Active Directory (Trust Relationship).

ğŸ‘‰ *[Voir le dossier d'architecture complet](docs/01-%20Choix%20des%20services%20AWS%20adaptÃ©s.md)*

---

## ğŸ’» PARTIE 2 : Pipeline ETL Streaming (ImplÃ©mentation POC)

**Contexte :** Pour valider la chaÃ®ne de traitement **Redpanda + Spark**, un POC (Proof of Concept) a Ã©tÃ© dÃ©veloppÃ© en local.
**DonnÃ©es :** Simulation d'un flux de **Tickets Support** (JSON) pour tester la transformation et le typage en temps rÃ©el.

### Architecture Technique du POC (Docker)

```mermaid
graph TD
    %% DÃ©finition des Styles
    classDef container fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef storage fill:#ffe0b2,stroke:#e65100,stroke-width:2px;
    classDef script fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px;

    subgraph DOCKER["DOCKER CLUSTER"]
        direction TB
        P(Producer Python):::script
        RP(Redpanda Broker):::container
        S(Spark Structured Streaming):::script
        
        P -->|"1. GÃ©nÃ¨re Tickets (JSON)"| RP
        RP -->|"2. Topic: client_tickets"| S
    end
    
    subgraph DATA["VOLUME PARTAGÃ‰"]
        DL[(Dossier data_output)]:::storage
    end

    subgraph LOCAL["ğŸ§ WSL / LOCAL"]
        M(Monitoring.py):::script
    end

    %% Flux de donnÃ©es
    S -->|"3. Nettoyage & Export Parquet"| DL
    P -.->|"Audit Logs"| DL
    
    %% Monitoring
    DL -.->|"4. ContrÃ´le Latence & QualitÃ©"| M
```

### FonctionnalitÃ©s ClÃ©s

*   **Ingestion :** Producer Python gÃ©nÃ©rant des tickets alÃ©atoires (Faker).
*   **Traitement :** Job Spark Streaming (PySpark 3.5) avec gestion des schÃ©mas et enrichissement (catÃ©gorisation des demandes).
*   **Stockage :** Ã‰criture au format **Parquet** avec gestion des Checkpoints.
*   **RÃ©silience :** Graceful Shutdown (arrÃªt propre) sur interception des signaux Docker.
*   **Monitoring :** Dashboard temps rÃ©el comparant l'entrÃ©e (Producer) et la sortie (Data Lake) pour mesurer le lag.

---

## ğŸ› ï¸ Installation & DÃ©marrage

### PrÃ©requis

*   **Docker** & **Docker Compose**
*   **Linux** ou **WSL2** recommandÃ©.

### 1. Cloner et Configurer

```bash
git clone https://github.com/votre-user/InduTechData.git
cd InduTechData

# CrÃ©er le fichier de configuration (valeurs par dÃ©faut optimisÃ©es)
cp .env.example .env
```

### 2. Lancer le Pipeline

```bash
docker-compose up --build
```

### 3. Lancer le Monitoring (Optionnel)

Pour visualiser l'avancement depuis votre terminal local :
```bash
# Installation des dÃ©pendances lÃ©gÃ¨res dev
pip install pandas pyarrow

# Lancement du dashboard
python src/monitoring.py
```

---

## ğŸ“‚ Structure du Projet

```text
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer.py       # GÃ©nÃ©rateur de tickets
â”‚   â”œâ”€â”€ stream_job.py     # ETL Spark Streaming
â”‚   â”œâ”€â”€ monitoring.py     # Dashboard de contrÃ´le local
â”‚   â””â”€â”€ config.py         # Config centralisÃ©e
â”œâ”€â”€ docs/                 # Documentation Architecture & FinOps
â”œâ”€â”€ data_output/          # Volume de sortie (Parquet + Checkpoints)
â”œâ”€â”€ Dockerfile            # Image unique optimisÃ©e (Python + Java + Spark)
â””â”€â”€ docker-compose.yml    # Orchestration
```

## ğŸ“š Documentation DÃ©taillÃ©e

*   ğŸ“„ **[Architecture Hybride & Choix Techniques](docs/01-%20Choix%20des%20services%20AWS%20adaptÃ©s.md)**
*   ğŸ“„ **[Analyse FinOps & CompatibilitÃ© SI](docs/02-%20Evaluation%20de%20compatibilitÃ©%20SI.md)**
*   ğŸ¥ **DÃ©mo VidÃ©o :** *[Lien Youtube Ã  venir]*

---

## ğŸ‘¤ Auteur

**Abdulkadir GUVEN** - Data Engineer Student

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/abguven/)
